---
title: "Introduction to data analysis in R. Day 1."
output:
  html_document:
    toc: yes
    number_sections: yes
    theme: united
date: '2022-05-26'
---

```{r setup, include=FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Gettings started with R



## What is R?

R is a powerful language and environment for *statistical computing and graphics*. It is a public domain (a so called “GNU”) project which is similar to the commercial S language and environment which was developed at Bell Laboratories (formerly AT&T, now Lucent Technologies) by John Chambers and colleagues. R can be considered as a different implementation of S, and is much used in as an educational language and research tool.

The main advantages of R are the fact that R is freeware and that there is a lot of help available online. It is quite similar to other programming packages such as MatLab (not freeware), but more user-friendly than programming languages such as C++ or Fortran. You can use R as it is, but for educational purposes we prefer to use R in combination with the RStudio interface (also freeware), which has an organized layout and several extra options.

For more details on R see their official website <https://www.r-project.org/>.

## Installation

We'll need to install two things: *R base* and *IDE* (Integrated Development Environment).

1. Install **R base**.

    a. For Windows users select the [Download R for Windows](https://cran.r-project.org/bin/windows/){target="_blank"} link and then click on         the "base" link and finally the download link "Download R 4.1.3 for Windows". This will begin the download of the             ".exe" installation file. When the download has completed double click on the R executable file and follow the                on-screen instructions.
    
    b. For Mac users select the [Download R for (Mac) OS X](https://cran.r-project.org/bin/macosx/){target="_blank"} link. The binary can be          downloaded by selecting the "R-4.2.0.pkg". Once downloaded, double click on the file icon and follow the                      on-screen instructions to guide you through the necessary steps. 
       See the [R for Mac OS X FAQ](https://cran.r-project.org/bin/macosx/){target="_blank"} for further information on installation.
       
   *Testing R installation*
   
   Whichever operating system you’re using, once you have installed R you need to check its working properly. The easiest way    to do this is to start R by double clicking on the R icon (Windows or Mac) or by typing R into the Console (Linux). You       should see the R Console and you should be able to type R commands into the Console after the command prompt >. Try typing    the following R code and then press enter (don’t worry of you don’t understand this - we’re just checking if R works)

    ```{r}
    plot(1:10)
    ```
    
    A plot of the numbers 1 to 10 on both the x and y axes should appear. If you see this, you’re good to go. 

2. Install **RStudio**.

    Whilst its eminently possible to just use the base installation of R (many people do), we will be using a popular **I**ntegrated **D**evelopment **E**nvironment (IDE) called RStudio. RStudio can be thought of as an add-on to R which provides a more user-friendly interface, incorporating the R Console, a script editor and other useful functionality (like R markdown and Git Hub integration). You can find more information about [RStudio here](https://www.rstudio.com/){target="_blank"}.
  
    RStudio is freely available for Windows, Mac and Linux operating systems and can be downloaded from the [RStudio site](https://www.rstudio.com/products/rstudio/download/){target="_blank"}. You should select the ‘RStudio Desktop’ version. Note: you must install R before you install RStudio (see previous section for details).
    
    *Testing RStudio*
    
    Once installed, you can check everything is working by starting up RStudio (you don’t need to start R as well, just RStudio).

    The large window (aka pane) on the left is the Console window. The window on the top right is the Environment / History / Connections pane and the bottom right window is the Files / Plots / Packages / Help / Viewer window. You can customise the location of each pane by clicking on the "Tools" menu then selecting Global Options –> Pane Layout. You can resize the panes by clicking and dragging the middle of the window borders in the direction you want. There are a plethora of other ways to customise RStudio.


## RStudio

<!-- The last thing is recommended to do is select `Tools -> Project Options...` from the menu. Click on the ‘General’ tab on the left hand side and then change the values for ‘Restore .RData into workspace at startup’ and ‘Save workspace to .RData on exit’ from ‘Default’ to ‘No’. This ensures that every time you open your project you start with a clean R session. You don’t have to do this (many people don’t) but it is better to start with a completely clean workspace whenever we open our projects to avoid any potential conflicts with things we have done in previous sessions. The downside to this is that you will need to rerun your R code every time you open you project. -->

### Console

The Console is the workhorse of R. This is where R evaluates all the code you write. You can type R code directly into the Console at the command line prompt. For example, if you type `2 + 2` into the Console you should obtain the answer `4`. Don’t worry about the [1] at the start of the line for now.

However, once you start writing more R code this becomes rather cumbersome. Instead of typing R code directly into the Console a better approach is to create an **R script**. An **R script** is just a plain text file with a .R file extension which contains your lines of R code. These lines of code are then sourced into the R Console line by line. To create a new R script click on the ‘File’ menu then select *New File* –> *R Script*.

To source your code from your script editor to the Console simply place your cursor on the line of code and then click on the ‘Run’ button in the top right of the script editor pane.


### Environment / History / Connections

The Environment / History / Connections window shows you lots of useful information. You can access each component by clicking on the appropriate tab in the pane.

- The ‘Environment’ tab displays all the objects you have created in the current (global) environment. These objects can be things like data you have imported or functions you have written. Objects can be displayed as a List or in Grid format by selecting your choice from the drop down button on the top right of the window. If you’re in the Grid format you can remove objects from the environment by placing a tick in the empty box next to the object name and then click on the broom icon. There’s also an ‘Import Dataset’ button which will import data saved in a variety of file formats. However, we would suggest that you don’t use this approach to import your data as it’s not reproducible and therefore not robust.

- The ‘History’ tab contains a list of all the commands you have entered into the R Console. You can search back through your history for the line of code you have forgotten, send selected code back to the Console or Source window. We usually never use this as we always refer back to our R script.

- The ‘Connections’ tab allows you to connect to various data sources such as external databases.


### Files/Plots/Packages/Help/Viewer

- The ‘Files’ tab lists all external files and directories in the current working directory on your computer. It works like file explorer (Windows) or Finder (Mac). You can open, copy, rename, move and delete files listed in the window.

- The ‘Plots’ tab is where all the plots you create in R are displayed (unless you tell R otherwise). You can ‘zoom’ into the plots to make them larger using the magnifying glass button, and scroll back through previously created plots using the arrow buttons. There is also the option of exporting plots to an external file using the ‘Export’ drop down menu. Plots can be exported in various file formats such as jpeg, png, pdf, tiff or copied to the clipboard.

- The ‘Packages’ tab lists all of the packages that you have installed on your computer. You can also install new packages and update existing packages by clicking on the ‘Install’ and ‘Update’ buttons respectively.

- The ‘Help’ tab displays the R help documentation for any function.

- The ‘Viewer’ tab displays local web content such as web graphics generated by some packages.


## R packages

The base installation of R comes with many useful **packages** as standard. These packages will contain many of the functions you will use on a daily basis. However, as you start using R for more diverse projects (and as your own use of R evolves) you will find that there comes a time when you will need to extend R’s in-built capabilities. Happily, many thousands of R users have developed useful code and shared this code as installable packages. You can think of a **package** as a *collection of functions, data and help files* collated into a well defined standard structure which you can download and install in R. These packages can be downloaded from a variety of sources but the most popular are CRAN, Bioconductor and GitHub. Currently, CRAN hosts over 15 000 packages and is the official repository for user contributed R packages. 

### Installing and updating packages

To install a package from CRAN you can use the `install.packages()` function. For example if you want to install the `remotes` package enter the following code into the Console window of RStudio (note: you will need a working internet connection to do this)

```{r, eval=FALSE}
install.packages('remotes', dependencies = TRUE)
```

It’s good practice to occasionally update your previously installed packages to get access to new functionality and bug fixes. To update CRAN packages you can use the `update.packages()` function (you will need a working internet connection for this)

```{r, eval=FALSE}
update.packages(ask = FALSE)
```

You may be asked to select a CRAN mirror, just select ‘0-cloud’ or a mirror near to your location. The `dependencies = TRUE` argument ensures that additional packages that are required will also be installed.

### Using packages

Once you have installed a package onto your computer it is not immediately available for you to use. To use a package you first need to load the package by using the library() function. For example, to load the remotes package you previously installed

```{r, eval=FALSE}
library(remotes)
```

## R projects

A great way of keeping things organised is to use RStudio Projects. An RStudio Project keeps all of your R scripts, R markdown documents, R functions and data together in one place. The nice thing about RStudio Projects is that each project has its own directory, workspace, history and source documents so different analyses that you are working on are kept completely separate from each other. This means that you can have multiple instances of RStudio open at the same time (if that’s your thing) or you can switch very easily between projects without fear of them interfering with each other.

As part of our project, we have created a `r.Rproj` file in `./data-science-workshop-2022/r/` directory.

## Working directories

The working directory is the default location where R will look for files you want to load and where it will put any files you save. One of the great things about using RStudio Projects is that when you open a project it will automatically set your working directory to the appropriate location. You can check the file path of your working directory by looking at bar at the top of the Console pane.

Additionally, you can use the `getwd()` function which returns the file path of the current working directory.

If you are not using RStudio, you have to set your working directory everytime you start the R console:

```{r, eval=FALSE}
setwd('/Users/Documents/Liubomyr/Teaching/first_project')
```

Remember, `setwd()` uses an *absolute* path which is specific to the computer you are working on.


By properly setting up your working directory, you can access files on your machine and load them into the environment!

```{r}
library(knitr)

initial_data <- read.table('./data/raw_data/mafic_dykes.csv', header=TRUE, sep=',')
kable(initial_data[5:10,], caption='A sample table of XRF and ICP analyses of mafic dykes.')
```


## Directory structure

Typically, I prefer putting all data in a separate folder `data`, scripts into a root of the project or a folder `scripts`,
outputs (visualizations, tables, calculations, etc.) in a folder `output`... you got the idea. Accordingly:

- **Root** - This is a project directory containing your .Rproj file. In our case it's `./data-science-workshop-2022/r/`

- **data** - We store all our data in this directory. The subdirectory called `raw_data` contains raw data files and only raw data files. These files should be treated as read only and should not be changed in any way. If you need to process/clean/modify your data do this in R (not MS Excel) as you can document (and justify) any changes made. Any processed data should be saved to a separate file and stored in the `processed_data` subdirectory. Information about data collection methods, details of data download and any other useful metadata could be saved in a text document (see README text files below) in the metadata subdirectory.

- **R** - This is an optional directory where we save all of the custom R functions we’ve written for the current analysis. These can then be sourced into R using the `source()` function.

- **scripts** - All of the main R scripts we have written for the current project are saved here.

- **output** - Outputs from our R scripts such as plots, HTML files and data summaries are saved in this directory. This helps us and our collaborators distinguish what files are outputs and which are source files.


## File naming conventions

- **Avoid using spaces** in file names by replacing them with underscores or even hyphens. Why does this matter? One reason is that some command line software (especially many bioinformatic tools) won’t recognise a file name with a space and you’ll have to go through all sorts of shenanigans using escape characters to make sure spaces are handled correctly. Another good reason not to use spaces in file names is that it makes searching for file names (or parts of file names) using regular expressions in R (or any other language) much more difficult.

- For the reasons given above, also **avoid using special characters** (i.e. @£$%^&*(:/) in your file names.

- If you are **versioning your files with sequential numbers** (i.e. file1, file2, file3 …) and you have more than 9 files you should use 01, 02, 03 .. 10 as this will ensure the files are printed in the correct order (see what happens if you don’t). If you have more than 99 files then use 001, 002, 003… etc.

- If your file names include dates, **use the ISO 8601 format YYYY-MM-DD (or YYYYMMDD)** to ensure your files are listed in proper chronological order.

**Never use the word final in any file name - it never is**!

## Project documentation

It is a good practice to document your functions or whole projects. The comments or documentation should allow the developers unfamiliar with your code to quickly understand what the function does and easily navigate across the project files.


Here’s an example of including meta-information at the start of an R script

```{r, eval=FALSE}
# Title: Exploratory analysis of geochemical data of mafic dykes from 22nd Antarctic expedition

# Purpose : This script performs basic data analysis
#           of geochemical data of mafic dykes.
#           The samples include 11 basalts and 4 lamprophyres.
#           The data is XRF and ICP-MS analyses.


# Author: Liubomyr Gavryliv
# Contact details: liubomyr.gavryliv@uniba.sk

# Date script created: Mon Dec 2 16:06:44 2021 -----------
# Date script last modified: Thu Dec 12 16:07:12 2021 ----


library(PopSnouter)
library(ggplot2)

print('put your lovely R code here')

# good practice to include session information

xfun::session_info()
```


## R style guide

How you write your code is more or less up to you although your goal should be to make it as easy to read as possible (for you and others). Whilst there are no rules (and no code police), we encourage you to get into the habit of writing readable R code by adopting a particular style. We suggest that you follow Google’s [R style guide](https://google.github.io/styleguide/Rguide.html) whenever possible.


# R basics

Before we continue, here are a few things to bear in mind as you work through this Chapter:

- R is case sensitive i.e. `A` is not the same as `a` and `anova` is not the same as `Anova`.

- Anything that follows a `#` symbol is interpreted as a comment and ignored by R. Comments should be used liberally throughout your code for both your own information and also to help your collaborators. Writing comments is a bit of an art and something that you will become more adept at as your experience grows.

- In R, commands are generally separated by a new line. You can also use a semicolon `;` to separate your commands but this is rarely used.

- If a continuation prompt `+` appears in the console after you execute your code this means that you haven’t completed your code correctly. This often happens if you forget to close a bracket and is especially common when nested brackets are used `((((some command)))`. Just finish the command on the new line and fix the typo or hit escape on your keyboard (see point below) and fix.


## Getting started

The `[1]` in front of the result tells you that the observation number at the beginning of the line is the first observation. This is not much help in this example, but can be quite useful when printing results with multiple lines (we’ll see an example below). The other obvious arithmetic operators are `-`, `*`, `/` for subtraction, multiplication and division respectively. R follows the usual mathematical convention of order of operations. 

There are a huge range of mathematical functions in R, some of the most useful include: `log()`, `log10()`, `exp()`, `sqrt()`.


## Objects in R

At the heart of almost everything you will do (or ever likely to do) in R is the concept that everything in R is an object. These objects can be almost anything, from a single number or character string (like a word) to highly complex structures like the output of a plot, a summary of your statistical analysis or a set of R commands that perform a specific task. Understanding how you create objects and assign values to objects is key to understanding R.


To create an object we simply give the object a name. We can then assign a value to this object using the *assignment operator* <- (sometimes called the *gets operator*). The assignment operator is a composite symbol comprised of a ‘less than’ symbol `<` and a hyphen `-` .

```{r, eval=FALSE}
some_object <- 50
```

You can also use `=` instead of `<-` to assign values but this is considered bad practice and we would discourage you from using this notation.

You can view the newly created object in the Environment panel or by typing the object name directly in the console.

Additionally, you can assign any data type to an object: `string`, `numbers`... and make simple operations with them!

```{r}
object_1 <- 50
object_2 <- 30

object_1 + object_2
```

### Naming objects

Naming your objects is one of the most difficult things you will do in R. Ideally your object names should be kept both short and informative which is not always easy. 

There are two major types of naming objects: **CamelCase** and **snake_case**.

If you need to create objects with multiple words in their name then use either an underscore or a dot between words or capitalise the different words. We prefer the underscore format (called *snake case*).

```{r, eval=FALSE}
output_summary <- "my geochemical analysis"
output.summary <- "my geochemical analysis"
outputSummary <- "my geochemical analysis"
```

There are also a few limitations when it come to giving objects names. An object name cannot start with a number or a dot followed by a number (i.e. `2my_variable` or `.2my_variable`). You should also avoid using non-alphanumeric characters in your object names (i.e. `&`, `^`, `/`, `!` etc). In addition, make sure you don’t name your objects with reserved words (i.e. `TRUE`, `NA`) and it’s never a good idea to give your object the same name as a built-in function.

## Using functions

A function as an **object** which contains a series of instructions to perform a specific task. R has a lot of built-in primitive functions, which could be treated as **base** functions.

The function name is always followed by a pair of round brackets even if there’s nothing contained between the brackets. Secondly, the argument(s) of a function are placed inside the round brackets and are separated by commas.


1. `c()` - a generic function which combines its arguments. The function is short for concatenate and we use it to join together a series of values and store them in a data structure called a vector. A **vector** is a basic data structure in R. It contains element of the same type. The data types can be *logical*, *integer*, *double*, *character*, *complex* or *raw*.

```{r, eval=FALSE}
some_vec <- c(2, 3, 1, 6, 4, 3, 3, 7)
```

2. Mathematical functions: `mean()`, `median()`, `var()`, `sd()`.

```{r, eval=FALSE}
mean(some_vec)    # returns the mean of some_vec
## [1] 3.625
var(some_vec)     # returns the variance of some_vec
## [1] 3.982143
sd(some_vec)      # returns the standard deviation of some_vec
## [1] 1.995531
length(some_vec)  # returns the number of elements in some_vec
## [1] 8

```

3. Other useful functions: `length()`, `seq()`, `rep()`.

```{r, eval=FALSE}
my_seq <- 1:10     # create regular sequence
my_seq
##  [1]  1  2  3  4  5  6  7  8  9 10
my_seq2 <- 10:1    # in descending order
my_seq2
##  [1] 10  9  8  7  6  5  4  3  2  1
```


## Working with vectors

Manipulating, summarising and sorting data using R is an important skill to master but one which many people find a little confusing at first. We’ll go through a few simple examples here using vectors to illustrate some important concepts but will build on this in much more detail later on.

### Extracting (or indexing, or subscripting) elements

In order to select one or more elements from a vector, we use square bracket `[ ]` notation. We can extract elements by their position or by satisfying some logical operation.

1. **Positional** index.

**Note that the positional index starts at 1 rather than 0 like some other other programming languages (i.e. Python).**

To extract elements based on their position we simply write the position inside the [ ]. For example, to extract the 3rd value of my_vec

```{r, eval=FALSE}
my_vec <-  c(2, 3, 1, 6, 4, 3, 3, 7)
my_vec[3]     # extract the 3rd value
## [1] 1
```

We can also extract more than one value by using the `c()` function inside the square brackets. Here we extract the 1st, 5th, 6th and 8th element from the `my_vec` object:

```{r, eval=FALSE}
my_vec[c(1, 5, 6, 8)]
## [1] 2 4 3 7
```

Or we can extract a range of values using the `:` notation. To extract the values from the 3rd to the 8th elements:

```{r, eval=FALSE}
my_vec[3:8]
## [1] 1 6 4 3 3 7
```

2. **Logical** index.

Another useful way to extract data from a vector is to use a logical expression as an index. For example, to extract all elements with a value greater than 4 in the vector `my_vec`:

```{r, eval=FALSE}
my_vec[my_vec > 4]
## [1] 6 7
```

Here, the logical expression is `my_vec > 4` and R will only extract those elements that satisfy this logical condition. 

So how does this actually work? If we look at the output of just the logical expression without the square brackets you can see that R returns a vector containing either TRUE or FALSE which correspond to whether the logical condition is satisfied for each element. In this case only the 4th and 8th elements return a TRUE as their value is greater than 4.

```{r, eval=FALSE}
my_vec > 4
## [1] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE
```

In addition to `<` and `>` operators you can increase the complexity.

```{r, eval=FALSE}
my_vec[my_vec >= 4]        # values greater or equal to 4
## [1] 6 4 7
my_vec[my_vec < 4]         # values less than 4
## [1] 2 3 1 3 3
my_vec[my_vec <= 4]        # values less than or equal to 4
## [1] 2 3 1 4 3 3
my_vec[my_vec == 4]        # values equal to 4
## [1] 4
my_vec[my_vec != 4]        # values not equal to 4
## [1] 2 3 1 6 3 3 7
```

We can also combine multiple logical expressions using Boolean expressions. In R the `&` symbol means AND and the `|` symbol means OR. For example, to extract values in `my_vec` which are less than 6 AND greater than 2.

```{r, eval=FALSE}
val_filtered <- my_vec[(my_vec < 6) & (my_vec > 2)]
val_filtered
## [1] 3 4 3 3
```


### Replacing elements

We can change the values of some elements in a vector using our `[ ]` notation in combination with the assignment operator `<-`. For example, to replace the 4th value of our `my_vec` object from 6 to 500:

```{r, eval=FALSE}
my_vec[4] <- 500
my_vec
## [1]   2   3   1 500   4   3   3   7
```


We can also replace more than one value or even replace values based on a logical expression!


### Ordering elements

We can order the elements in a vector by using in-built `sort()` function:

```{r, eval=FALSE}
sort(my_vec)
## [1]    7  100  100  500 1000 1000 1000 1000
```

To reverse the sort, from highest to lowest, we can either include the `decreasing = TRUE` argument when using the `sort()` function

```{r, eval=FALSE}
sort(my_vec, decreasing = TRUE)
## [1] 1000 1000 1000 1000  500  100  100    7
```

What if we need to sort values based on some other vector? For example, sort a series of rock types based on the MgO? We can use another in-built function `order()` which returns indexes instead of values.

```{r, eval=FALSE}
rock.types = c('basalt', 'andesite', 'dacite', 'anorthosite', 'dunite')
mgo.measured = c(8, 6, 2, 10, 12)

mgo.measured.asc = order(mgo.measured)
rock.types[mgo.measured.asc]

## [1] "dacite"      "andesite"    "basalt"      "anorthosite" "dunite"
```

### Vectorisation

One of the great things about R functions is that most of them are *vectorised*. This means that the function will operate on all elements of a vector without needing to apply the function on each element separately.

```{r, eval=FALSE}
# create a vector
my_vec2 <- c(3, 5, 7, 1, 9, 20)

# multiply each element by 5
my_vec2 * 5
## [1]  15  25  35   5  45 100
```

Or we can add the elements of two or more vectors:

```{r, eval=FALSE}
# create a second vector
my_vec3 <- c(17, 15, 13, 19, 11, 0)

# add both vectors
my_vec2 + my_vec3
## [1] 20 20 20 20 20 20

# multiply both vectors
my_vec2 * my_vec3
## [1] 51 75 91 19 99  0
```

**Be careful when using vectorisation with vectors of different lengths!**

### Missing data

In R, missing data is usually represented by an `NA` symbol meaning ‘Not Available’. Data may be missing for a whole bunch of reasons, maybe your machine broke down, maybe you broke down, maybe the weather was too bad to collect data on a particular day etc etc. Missing data can be a pain in the proverbial both from an R perspective and also a statistical perspective.

```{r, eval=FALSE}
my_vec <- c(17, 15, 13, 19, 11, 0, NA)
mean(my_vec)
# [1] NA
```

However, if we change this argument to n`a.rm = TRUE` when we use the `mean()` function this will allow us to ignore the `NA` values when calculating the mean:
```{r, eval=FALSE}
my_vec <- c(17, 15, 13, 19, 11, 0, NA)
mean(my_vec, na.rm = TRUE)
# [1] 12.5
```

## Getting help

The best place to start learning and understand what each function does is **reading the documentation**. Always check it!

There are two principal ways to open the documentation of a specific function:

1. `help("mean")`
2. `?mean`

However, if you don't remember the exact name of the function, but remember the keyword you can still search R's help system using these
methods:

1. `help.search("mean")`
2. `??mean`

Another useful function is `apropos()`. This function can be used to list all functions containing a specified character string. For example, to find all functions with mean in their name:

```{r, eval=FALSE}
apropos("mean")
##  [1] ".colMeans"     ".rowMeans"     "colMeans"      "kmeans"       
##  [5] "mean"          "mean_temp"     "mean.Date"     "mean.default" 
##  [9] "mean.difftime" "mean.POSIXct"  "mean.POSIXlt"  "rowMeans"     
## [13] "vec_mean"      "weighted.mean"
```

# Exercises

## Task

Use R to determine the area of a circle with a diameter of 20 cm and assign the result to a variable called `area_circle`. 

**Google is your friend if you can’t remember the formula 🙂 Also, remember that R already knows about pi.**


## Task

Calculate the cube root of 14 x 0.51. You might need to think creatively for a solution, and remember that R follows the usual order of mathematical operators so you might need to use brackets in your code.


## Task

Let's get back to geological dimension 😊!

Create a vector of dummy MgO analyses of your favorite rocks. Remember, that a vector is of 1 dimension and stores
values of one data type only. You can use function `c()` to create new vector.

Now, calculate some basic stats of your MgO:

- min of MgO
- max of MgO
- mean of MgO
- subset your vector by values above the mean

# Data in R

There are few major data types in R:

- **Numeric** data are numbers that contain a decimal. Actually they can also be whole numbers but we’ll gloss over that.

- **Integers** are whole numbers (those numbers without a decimal point).

- **Logical data** take on the value of either `TRUE` or `FALSE`. There’s also another special type of logical called NA to represent missing values.

- **Character** data are used to represent string values. You can think of character strings as something like a word (or multiple words). A special type of character string is a factor, which is a string but with additional attributes (like levels or an order). We’ll cover factors later.

R is (usually) able to automatically distinguish between different classes of data by their nature and the context in which they’re used although you should bear in mind that R can’t actually read your mind and you may have to explicitly tell R how you want to treat a data type. You can find out the type (or class) of any object using the class() function.

```{r, eval=FALSE}
num <- 2.2
class(num)
## [1] "numeric"

char <- "hello"
class(char)
## [1] "character"

logi <- TRUE
class(logi)
## [1] "logical"
```
Alternatively, you can ask if an object is a specific class using using a logical test. The `is.[classOfData]()` family of functions will return either a `TRUE` or a `FALSE`.

```{r, eval=FALSE}
is.numeric(num)
## [1] TRUE

is.character(num)
## [1] FALSE

is.character(char)
## [1] TRUE

is.logical(logi)
## [1] TRUE
```

It can sometimes be useful to be able to change the class of a variable using the `as.[className]()` family of coercion functions, although you need to be careful when doing this as you might receive some unexpected results (see what happens below when we try to convert a character string to a numeric).

```{r, eval=FALSE}
# coerce numeric to character
class(num)
## [1] "numeric"
num_char <-  as.character(num)
num_char
## [1] "2.2"
class(num_char)
## [1] "character"

# coerce character to numeric!
class(char)
## [1] "character"
char_num <- as.numeric(char)
## Warning: NAs introduced by coercion
```


## Data structures

Now that you know about data types, let's see where we can store these data.

### Scalars and vectors

Perhaps the simplest type of data structure is the **vector**. Vectors that have a single value (length 1) are called **scalars**. Vectors can contain numbers, characters, factors or logicals, but the key thing to remember is that all the elements inside a vector must be of the same class. In other words, vectors can contain either numbers, characters or logicals but not mixtures of these types of data. There is one important exception to this, you can include NA (remember this is special type of logical) to denote missing data in vectors with other data types.

### Matrices and arrays

Another useful data structure used in many disciplines is the **matrix**. A **matrix** is simply a vector that has additional attributes called dimensions. **Arrays** are just multidimensional matrices. **Again, matrices and arrays must contain elements all of the same data class**.

A convenient way to create a matrix or an array is to use the `matrix()` and `array()` functions respectively. Below, we will create a matrix from a sequence 1 to 16 in four rows `(nrow = 4)` and fill the matrix row-wise `(byrow = TRUE)` rather than the default column-wise. When using the `array()` function we define the dimensions using the `dim = argument`, in our case 2 rows, 4 columns in 2 different matrices.

``` {r, eval=FALSE}
my_mat <- matrix(1:16, nrow = 4, byrow = TRUE)
my_mat
##      [,1] [,2] [,3] [,4]
## [1,]    1    2    3    4
## [2,]    5    6    7    8
## [3,]    9   10   11   12
## [4,]   13   14   15   16

my_array <- array(1:16, dim = c(2, 4, 2))
my_array
## , , 1
## 
##      [,1] [,2] [,3] [,4]
## [1,]    1    3    5    7
## [2,]    2    4    6    8
## 
## , , 2
## 
##      [,1] [,2] [,3] [,4]
## [1,]    9   11   13   15
## [2,]   10   12   14   16
```

Sometimes it’s also useful to define row and column names for your matrix but this is not a requirement. To do this use the `rownames()` and `colnames()` functions.

``` {r, eval=FALSE}
rownames(my_mat) <- c("SiO2", "Na2O", "K2O", "MgO")
colnames(my_mat) <- c("a", "b", "c", "d")
my_mat
##    a  b  c  d
## SiO2  1  2  3  4
## Na2O  5  6  7  8
## K2O   9 10 11 12
## MgO  13 14 15 16
```

Once you’ve created your matrices you can do useful stuff with them and as you’d expect, R has numerous built in functions to perform matrix operations. Some of the most common are:
- the transposition function `t()`
- the extraction of the diagonal elements of a matrix using the `diag()` function

The usual matrix addition, multiplication etc can be performed. Note the use of the %*% operator to perform matrix multiplication.

``` {r, eval=FALSE}
mat.1 <- matrix(c(2, 0, 1, 1), nrow = 2)    # notice that the matrix has been filled 
mat.1                                     # column-wise by default
##      [,1] [,2]
## [1,]    2    1
## [2,]    0    1

mat.2 <- matrix(c(1, 1, 0, 2), nrow = 2)
mat.2
##      [,1] [,2]
## [1,]    1    0
## [2,]    1    2

mat.1 + mat.2           # matrix addition
##      [,1] [,2]
## [1,]    3    1
## [2,]    1    3
mat.1 * mat.2           # element by element products
##      [,1] [,2]
## [1,]    2    0
## [2,]    0    2
mat.1 %*% mat.2         # matrix multiplication
##      [,1] [,2]
## [1,]    3    2
## [2,]    1    2
```


### Lists

The next data structure we will quickly take a look at is a **list**. Whilst vectors and matrices are constrained to contain data of the same type, **lists are able to store mixtures of data types**. In fact we can even store other data structures such as vectors and arrays within a list or even have a list of a list. This makes for a very flexible data structure which is ideal for storing irregular or non-rectangular data.

To create a list we can use the `list()` function. Note how each of the three list elements are of different classes (character, logical, and numeric) and are of different lengths.

``` {r, eval=FALSE}
list_1 <- list(c("basalt", "andesite", "dacite"),
               c(TRUE, TRUE, FALSE, TRUE, FALSE, FALSE),
               matrix(1:6, nrow = 3))
list_1
## [[1]]
## [1] "basalt" "andesite" "dacite"
## 
## [[2]]
## [1]  TRUE  TRUE FALSE  TRUE FALSE FALSE
## 
## [[3]]
##      [,1] [,2]
## [1,]    1    4
## [2,]    2    5
## [3,]    3    6
```

Elements of the list can also be named in two ways:

1. during the construction of the list

``` {r, eval=FALSE}
list_2 <- list(rocks = c("basalt", "andesite", "dacite"), 
               is.altered = c(TRUE, TRUE, FALSE, TRUE, FALSE, FALSE), 
               measurements = matrix(1:6, nrow = 3))
list_2
## $rocks
## [1] "basalt"  "andesite" "dacite"
## 
## $is.altered
## [1]  TRUE  TRUE FALSE  TRUE FALSE FALSE
## 
## $measurements
##      [,1] [,2]
## [1,]    1    4
## [2,]    2    5
## [3,]    3    6
```

2. after the list has been created using the `names()` function

``` {r, eval=FALSE}
names(list_1) <- c("rocks", "is.altered", "measurements")
list_1
## $rocks
## [1] "basalt"  "andesite" "dacite"
## 
## $is.altered
## [1]  TRUE  TRUE FALSE  TRUE FALSE FALSE
## 
## $measurements
##      [,1] [,2]
## [1,]    1    4
## [2,]    2    5
## [3,]    3    6
```


### Data frames

By far the most commonly used data structure to store data in is the **data frame**. A **data frame** is a powerful two-dimensional object made up of rows and columns which looks superficially very similar to a matrix. However, whilst matrices are restricted to containing data all of the same type, data frames can contain a mixture of different types of data. Typically, in a data frame each row corresponds to an individual observation and each column corresponds to a different measured or recorded variable. This setup may be familiar to those of you who use LibreOffice Calc or Microsoft Excel to manage and store your data. Perhaps a useful way to think about data frames is that they are essentially made up of a bunch of vectors (columns) with each vector containing its own data type but the data type can be different between vectors.

As an example, the data frame below contains the results of ICP and XRF analyses of mafic dykes from the Argentine Islands (West Antarctica). The data frame has 68 variables (columns) and each row represents an individual measurement (40 rows). 

The variables `analysis_type` and `rock_type` are factors (categorical variables). The `analysis_type` variable has 2 levels (XRF and ICP) and the `rock_type` level variable has 11 levels. The variables `specimen`, `location`, `country_rocks` and `notes` are characters. The other columns are numeric, however, as some of those contain '<' sign, they are coarced to characters by default.

```{r}
library(knitr)

initial_data <- read.table('./data/raw_data/mafic_dykes.csv', header=TRUE, sep=',')
kable(initial_data[1:10,], caption='A sample table of XRF and ICP analyses of mafic dykes.')
```

There are a couple of important things to bear in mind about data frames. These types of objects are known as **rectangular data (or tidy data) as each column must have the same number of observations**. Also, any missing data should be recorded as an NA just as we did with our vectors.

We can construct a data frame from existing data objects such as vectors using the `data.frame()` function. As an example, let's 
create three vectors `id`, `rock.type` and `is.altered`:

```{r}
ids = seq(1:5)
rocks = c('microgabbro', 'metagabbro', 'gabbronorite', 'hornblende gabbro', 'volynite')
altered = c(FALSE, TRUE, FALSE, FALSE, FALSE)

data_ <- data.frame(id=ids, rock.type=rocks, is.altered=altered)
data_
```

Useful functions when working with data frames:
- `dim()` - returns the dimensions of data frame
- `str()` - returns a summary of data frame, including factors, data types etc


## Importing the data

There is a bunch of in-built functions to import the tables in different formats, whether its
`.xlsx`, `.xls`, `.csv` or a `.txt` extension:

1. `read_table()` - a work hourse 🐎 of R.

Some useful arguments include `dec =` and `na.strings =`. The `dec =` argument allows you to change the default character (.) used for a decimal point. This is useful if you’re in a country where decimal places are usually represented by a comma (i.e. `dec = ","`). The `na.strings =` argument allows you to import data where missing values are represented with a symbol other than `NA`. This can be quite common if you are importing data from other statistical software such as Minitab which represents missing values as a `*` (`na.strings = "*"`).

2. `read_csv()` - import comma separated value (.csv) files and assumes that the data in columns are separated by a comma (it sets `sep = ","` by default). It also assumes that the first row of the data contains the variable names by default (it sets` header = TRUE` by default)

3. `read_csv2()` - assumes data are separated by semicolons and that a comma is used instead of a decimal point (as in many European countries).

4. `read.delim()` - is used to import tab delimited data and also assumes that the first row of the data contains the variable names by default.

Additionally, we can import the data using the `readr` package, which is part of [tidyverse](https://www.tidyverse.org/) ecosystem. However, more on that later!

## Wrangling data frames

Let's do something useful with our data 🤗!

First of all, let's remind ourselves what's the structure of `initial_data` data frame we imported earlier:

```{r}
initial_data <- read.table('./data/raw_data/mafic_dykes.csv', header=TRUE, sep=',')
str(initial_data)
```

To access the data in any of the variables (columns) in our data frame we can use the `$` notation. For example, to access the `analysis_type` variable in our analyses data frame we can use `initial_data$analysis_type`. This tells R that the `analysis_type` variable is contained within the data frame `initial_data`.

```{r}
initial_data$analysis_type
```

The latter will return a vector, which we may assign to some variable. Additionally, we can already calculate
some stats within our data 📊!

```{r}
summary(initial_data$SiO2)
```

```{r}
mean(initial_data$MgO)
```

### Indexes 

As with vectors, we can also access data in data frames using the square bracket notation `[ ]`. 

1. **Positional indexes**

To use positional indexes we have to write the position of the rows and columns we want to extract inside the `[ ]`. For example, if for some reason we wanted to extract the first value (1st row) of the `rock_type` variable (5th column) we can do this:

```{r, eval=FALSE}
initial_data[1, 5]
```

which is the same as this:

```{r, eval=FALSE}
initial_data$rock_type[1]
```

We can also extract values from multiple rows or columns by specifying these indexes as vectors inside the `[ ]`. To extract the first 10 rows and the first 4 columns we simple supply a vector containing a sequence from 1 to 10 for the rows index `(1:10)` and a vector from 1 to 4 for the column index `(1:4)`:

```{r, eval=FALSE}
initial_data[1:10, 1:4]
```

Or for non sequential rows and columns we can supply vectors of positions using the `c()` function:

```{r, eval=FALSE}
initial_data[c(1, 5, 12), c(1, 3, 6, 8)]
```

If you want to select all rows, but a specific columns, you can do this:

```{r, eval=FALSE}
initial_data[, 1:4]
```

If you wont to omit specific rows or columns, prepend `-` to a vector:

```{r, eval=FALSE}
initial_data[1:10, -c(1:4)]
```

We can also name the variables directly when using the square bracket [ ] notation:

```{r, eval=FALSE}
initial_data[1:10, c('specimen', 'rock_type')]
```

2. **Logical indexes**

Just like with vectors, we can subset data frames using logical operations:

```{r, eval=FALSE}
initial_data[initial_data$SiO2 > 50]
```

You can also pass exact values:

```{r, eval=FALSE}
initial_data[initial_data$rock_type == 'basalt', ]
```
... or use a negation:

```{r, eval=FALSE}
initial_data[initial_data$rock_type != 'basalt', ]
```
Additionally, you can concatenate multiple operators using `|` (OR) and `&` (AND) operators:
```{r, eval=FALSE}
initial_data[(initial_data$rock_type == 'basalt') | (initial_data$rock_type == 'diabase'), ]

initial_data[(initial_data$rock_type == 'basalt') & (initial_data$analysis_type == 'ICP'), ]
```

### Ordering data frames

There's a function `order()` that we can use to order the data frame by a variable:

```{r, eval=FALSE}
initial_data[order(initial_data$SiO2, decreasing = TRUE), ]
```

We can also order by multiple variables:
```{r, eval=FALSE}
initial_data[order(initial_data$SiO2, -initial_data$MgO), ]
```

If we wanted to order the data frame by any other categorical variable, we need to first change the order of our levels of that column factor in our data frame using the `factor()` function. Once we’ve done this we can then use the `order()` function as usual. 

```{r, eval=FALSE}
initial_data$analysis_type <- factor(initial_data$analysis_type, levels=c('ICP', 'XRF'))
```

...and then you can apply ordering to your data frames

```{r, eval=FALSE}
initial_data[order(initial_data$analysis_type),]
```

### Adding columns and rows

To simply append additional rows to an existing data frame we can use the `rbind()` function and to append columns the `cbind()` function. Let’s create a couple of test data frames to see this in action using the `data.frame()` function.


```{r, eval = FALSE}
df1 <- data.frame(specimen = 1:3, location = c('Peterman', 'Barchan', 'Galindez'),
                  rock_type = 'basalt')
df2 <- data.frame(specimen = 1:3, location = 'Forge Isl',
                   rock_type = 'andesite')

rbind(df1, df2)
```

or concatenate columns:

```{r, eval = FALSE}
df1 <- data.frame(specimen = 1:3, location = c('Peterman', 'Barchan', 'Galindez'),
                  rock_type = 'basalt')
df2 <- data.frame(location = 'Forge Isl')

cbind(df1, df2)
```

### Merging data frames

We can merge 2 data frames together using the `merge()` function:

```{r, eval = FALSE}
df1 <- data.frame(specimen = 1:3, location = c('Peterman', 'Barchan', 'Galindez'),
                  rock_type = 'basalt')
df2 <- data.frame(specimen = 1:3, SiO2 = c(46, 47.5, 50.8),
                  lab = 'ACME')

merge(df1, df2)
```

By default, the merging is performed using the column which is present in both cases - `specimen` in the previous case.
However, if the variable names that you want to base the merge on are different in each data frame (for example 'specimen' and 'Specimen') you can specify the names in the first data frame (known as `x`) and the second data frame (known as `y`) using the `by.x =` and `by.y =` arguments.

```{r, eval = FALSE}
df1 <- data.frame(specimen = 1:3, location = c('Peterman', 'Barchan', 'Galindez'),
                  rock_type = 'basalt')
df2 <- data.frame(Specimen = 1:3, SiO2 = c(46, 47.5, 50.8),
                  lab = 'ACME')

merge(df1, df2, by.x='specimen', by.y='Specimen')
```
**What will happen if you don't pass `by.x` and `by.y` arguments?**


# Exercises

## Task

Create a vector, named `my_vec` with 10 elements in it using `c()` and `seq()` functions. 

## Task

Create a matrix, named `my_matrix` with 5 rows and 4 columns in it using `matrix()` functions. Fill it with any elements you wish.

## Task

Assign your rows these names: "a", "b", "c", "d", "e".

## Task

Create a list, named `minerals_list`, using `list()` function, that consists of 3 named vectors: 

- `silicates` with two entries: 'beryl' and 'chrysoberyl'
- `oxides` with two entries: 'choloalite' and 'pascoite'
- `halides` with two entries: 'belloite' and 'bararite'

## Task

Create empty data frame, named `minerals_df`, using `data.frame()` function, that consists of 5 columns and 3 rows.
The columns are as follows: 
- id - *numeric*
- rock_name - *string*
- location - *string*
- note - *string*

Add few rows to it using `rbind()` function:

1. 1, 'basaltoid', 'Zelezna Studnicka', 'A dyke of basaltic composition intrudes a large pegmatite body.'.  
2. 1, 'andesitoid', 'Zelezna Studnicka', 'Andesite flow with a thickness of 3 m.'. 

# Summarizing the data frames

## `summary()`
There's a `summary()` function that outputs some useful stats. You can apply it for the whole dataframe or to subsets, or specific columns:

```{r, eval = FALSE}
summary(initial_data$MgO)
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
# 2.152   5.272   6.840   6.428   7.498  11.890 
```

## `table()`

Another useful function is `table()` that can be used to build contingency tables of different combinations of factor levels. For example, to count the number of observations for each level of `analysis_type`:

```{r, eval = FALSE}
table(initial_data$analysis_type)
# ICP XRF 
# 15  25 
```

You can pass multiple columns to that function and see some insight!

```{r, eval = FALSE}
table(initial_data$analysis_type, initial_data$rock_type)
#  andesite basalt diabase dioritic porphyrite lamprophyre megacrystic porphyrite metadiabase porphyritic diabase porphyritic
#  ICP        0      5       3                   0           1                      0           0                   0 
#  XRF        1     11       5                   1           1                      1           2                   1 
```

## `xtabs()`

Another powerful function is `xtabs()` that uses a formula notation `~` to build contingency tables with the cross-classifying variables separated by a `+` symbol on the right hand side of the formula. `xtabs()` also has a useful `data =` argument so you don’t have to include the data frame name when specifying each variable.

```{r, eval = FALSE}
xtabs(~ analysis_type, data = initial_data)
# ICP XRF 
# 15  25 
```

## `tapply()`

We can also **summarise** our data for each level of a factor variable. Let’s say we want to calculate the mean value of `SiO2` for each of our *ICP* and *XRF* levels of `analysis_type` column. To do this we will use the `mean()` function and apply this to the `SiO2` variable for each level of `analysis_type` using the `tapply()` function.

```{r, eval = FALSE}
tapply(initial_data$SiO2, initial_data$analysis_type, FUN=mean)
```
Additionally, we can pass multiple factors!

```{r, eval = FALSE}
tapply(initial_data$SiO2, list(initial_data$analysis_type, initial_data$rock_type), FUN=mean)
```
Moreover, you can pass `summary()` function as the argument too:

```{r, eval = FALSE}
tapply(initial_data$SiO2, initial_data$analysis_type, FUN=summary)
```

## `aggregate()`

Another really useful function for summarising data is the `aggregate()` function. The `aggregate()` function works in a very similar way to `tapply()` but is a bit more flexible.

For example, to calculate the mean of the variables `SiO2`, `TiO2`, and `K2O` for each level of `rock_type` we do:
```{r, eval = FALSE}
aggregate(list(SiO2 = initial_data$SiO2, TiO2 = initial_data$TiO2, K2O = initial_data$K2O), by = list(rock_type = initial_data$rock_type), FUN = mean)
```

# Exporting data

Say you calculated some important variables, or filtered your data frame. Now, you want to save it. 

```{r, eval=FALSE}
export_data <- initial_data[initial_data$rock_type %in% c('basalt', 'metadiabase'), ]
```

There's a helper function `write.table()` or `write.csv()` that can do that easily! The first argument is the data frame you want to export (`export_data` in our example). We then give the `filename` (with file extension) and the file path in either single or double quotes using the `file =` argument. In this example we’re exporting the data frame to a file called `basalt_metadiabase.csv` in the `data/export/` directory. The `col.names = TRUE` argument indicates that the variable names should be written in the first row of the file and the `row.names = FALSE` argument stops R from including the row names in the first column of the file. Finally, the `sep = "\t"` argument indicates that a Tab should be used as the delimiter in the exported file.

```{r, eval = FALSE}
write.csv(export_data, file = 'data/export/basalt_metadiabase.csv', row.names = FALSE)
```

**That's all for today!**
